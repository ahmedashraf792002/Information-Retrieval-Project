{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4168e9",
   "metadata": {},
   "source": [
    "                          Arabic and English Text Preprocessing \n",
    "Arabic Steps:\n",
    "\n",
    "1.regular expression\n",
    "\n",
    "2.word tokenize\n",
    "\n",
    "3.remove stopwords\n",
    "\n",
    "4.stemming\n",
    "\n",
    "    4.1 ISRIStemmer\n",
    "    4.2 SnowballStemmer\n",
    "\n",
    "5.WordNetLemmatizer\n",
    "\n",
    "6.POS\n",
    "\n",
    "English Steps:\n",
    "\n",
    "1.regular expression \n",
    "\n",
    "2.word tokenize\n",
    "\n",
    "3.remove stopwords\n",
    "\n",
    "4.stemming\n",
    "\n",
    "    4.1 PorterStemmer\n",
    "    4.2 SnowballStemmer\n",
    "5.WordNetLemmatizer\n",
    "\n",
    "6.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685831f",
   "metadata": {},
   "source": [
    "##### Import Libraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9c6755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ahmed\n",
      "[nltk_data]     Ashraf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ahmed\n",
      "[nltk_data]     Ashraf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,ISRIStemmer,PorterStemmer,SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de928aac",
   "metadata": {},
   "source": [
    "                                     Arabic\n",
    "ISRIStemmer                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ad8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arabic_text_preprocessing(text,flage=1):\n",
    "    '''\n",
    "    Flage Number\n",
    "    1: ISRIStemmer\n",
    "    2: SnowballStemmer\n",
    "    3: WordNetLemmatizer\n",
    "    4: POS\n",
    "    '''\n",
    "    text1=text\n",
    "    #The regular expression [^\\w\\s] is used to match any character that is not a word character (\\w) or a whitespace character (\\s).\n",
    "    text = re.sub(r'[^\\w\\s]', '',text)\n",
    "    #splitting sentence into tokens\n",
    "    text=word_tokenize(text.lower())\n",
    "    #remove stopwords\n",
    "    arabic_stop=set(stopwords.words('arabic'))\n",
    "    text=[i for i in text if i not in arabic_stop]\n",
    "    #stemming of each word\n",
    "    if flage<=3:\n",
    "        if flage==1:\n",
    "            stem=ISRIStemmer()\n",
    "            text=[stem.stem(i) for i in text]\n",
    "            print('Perform ISRStemmer')\n",
    "        elif flage==2:\n",
    "            stem=SnowballStemmer('arabic')\n",
    "            text=[stem.stem(i) for i in text]\n",
    "            print('Perform SnowballStemmer')\n",
    "        else:\n",
    "            #Lemmatizer of each word\n",
    "            lemmatizer=WordNetLemmatizer()\n",
    "            text=[lemmatizer.lemmatize(i) for i in text]\n",
    "            print('Perform WordNetLemmatizer')\n",
    "        print(\"text before :\",text1)\n",
    "        print('text after :',' '.join(text))\n",
    "        print('text after tokens :',text)\n",
    "    else:\n",
    "        #part of speech of each word\n",
    "        text=nltk.pos_tag(text)\n",
    "        print('Preform POS')\n",
    "        print(\"text before :\",text1)\n",
    "        print('text after tokens :',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47575d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mArabic_text_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Flage Number\n",
       "1: ISRIStemmer\n",
       "2: SnowballStemmer\n",
       "3: WordNetLemmatizer\n",
       "4: POS\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\ahmed ashraf\\appdata\\local\\temp\\ipykernel_7408\\3698319348.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@Arabic_text_preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3b8b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform ISRStemmer\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \n",
      "text after : ÙŠØ¯Ø± Ø´Ø±Ø¹ Ø®Ø±Ø¬ Ø­Ù…Ø¯ Ø´Ø±Ù Ø­Ù…Ø¯ Ø³ÙŠØ¯ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒ 8 Ø´Ø®Øµ ÙŠØ¯Ø±\n",
      "text after tokens : ['ÙŠØ¯Ø±', 'Ø´Ø±Ø¹', 'Ø®Ø±Ø¬', 'Ø­Ù…Ø¯', 'Ø´Ø±Ù', 'Ø­Ù…Ø¯', 'Ø³ÙŠØ¯', 'ÙˆÙƒØ§Ù†', 'ØªÙŠÙ…', 'ÙŠØªÙƒ', '8', 'Ø´Ø®Øµ', 'ÙŠØ¯Ø±']\n"
     ]
    }
   ],
   "source": [
    "Arabic_text_preprocessing(\"Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \",flage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420c4d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the Arabic text you want to process:  Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform ISRStemmer\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n",
      "text after : ÙŠØ¯Ø± Ø´Ø±Ø¹ Ø®Ø±Ø¬ Ø­Ù…Ø¯ Ø´Ø±Ù Ø­Ù…Ø¯ Ø³ÙŠØ¯ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒ 8 Ø´Ø®Øµ ÙŠØ¯Ø±\n",
      "text after tokens : ['ÙŠØ¯Ø±', 'Ø´Ø±Ø¹', 'Ø®Ø±Ø¬', 'Ø­Ù…Ø¯', 'Ø´Ø±Ù', 'Ø­Ù…Ø¯', 'Ø³ÙŠØ¯', 'ÙˆÙƒØ§Ù†', 'ØªÙŠÙ…', 'ÙŠØªÙƒ', '8', 'Ø´Ø®Øµ', 'ÙŠØ¯Ø±']\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the Arabic text you want to process: \")\n",
    "Arabic_text_preprocessing(input_text,flage=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056483f3",
   "metadata": {},
   "source": [
    "SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ddeb21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform SnowballStemmer\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \n",
      "text after : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø³ÙŠØ¯ ÙˆÙƒØ§ ØªÙŠÙ… ÙŠØªÙƒÙˆ 8 Ø§Ø´Ø®Ø§Øµ Ù„ÙŠØ¯Ø±\n",
      "text after tokens : ['Ù„ÙŠØ¯Ø±', 'Ù…Ø´Ø±ÙˆØ¹', 'ØªØ®Ø±Ø¬', 'Ø§Ø­Ù…Ø¯', 'Ø§Ø´Ø±Ù', 'Ø§Ø­Ù…Ø¯', 'Ø³ÙŠØ¯', 'ÙˆÙƒØ§', 'ØªÙŠÙ…', 'ÙŠØªÙƒÙˆ', '8', 'Ø§Ø´Ø®Ø§Øµ', 'Ù„ÙŠØ¯Ø±']\n"
     ]
    }
   ],
   "source": [
    "Arabic_text_preprocessing(\"Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \",flage=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb52e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the Arabic text you want to process:  Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform SnowballStemmer\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n",
      "text after : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø³ÙŠØ¯ ÙˆÙƒØ§ ØªÙŠÙ… ÙŠØªÙƒÙˆ 8 Ø§Ø´Ø®Ø§Øµ Ù„ÙŠØ¯Ø±\n",
      "text after tokens : ['Ù„ÙŠØ¯Ø±', 'Ù…Ø´Ø±ÙˆØ¹', 'ØªØ®Ø±Ø¬', 'Ø§Ø­Ù…Ø¯', 'Ø§Ø´Ø±Ù', 'Ø§Ø­Ù…Ø¯', 'Ø³ÙŠØ¯', 'ÙˆÙƒØ§', 'ØªÙŠÙ…', 'ÙŠØªÙƒÙˆ', '8', 'Ø§Ø´Ø®Ø§Øµ', 'Ù„ÙŠØ¯Ø±']\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the Arabic text you want to process: \")\n",
    "Arabic_text_preprocessing(input_text,flage=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32618e",
   "metadata": {},
   "source": [
    "WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55424248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform WordNetLemmatizer\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \n",
      "text after : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† 8 Ø§Ø´Ø®Ø§Øµ Ø§Ù„Ù„ÙŠØ¯Ø±\n",
      "text after tokens : ['Ù„ÙŠØ¯Ø±', 'Ù…Ø´Ø±ÙˆØ¹', 'Ø§Ù„ØªØ®Ø±Ø¬', 'Ø§Ø­Ù…Ø¯', 'Ø§Ø´Ø±Ù', 'Ø§Ø­Ù…Ø¯', 'Ø§Ù„Ø³ÙŠØ¯', 'ÙˆÙƒØ§Ù†', 'ØªÙŠÙ…', 'ÙŠØªÙƒÙˆÙ†', '8', 'Ø§Ø´Ø®Ø§Øµ', 'Ø§Ù„Ù„ÙŠØ¯Ø±']\n"
     ]
    }
   ],
   "source": [
    "Arabic_text_preprocessing(\"Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \",flage=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a88374c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the Arabic text you want to process:  Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform WordNetLemmatizer\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n",
      "text after : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† 8 Ø§Ø´Ø®Ø§Øµ Ø§Ù„Ù„ÙŠØ¯Ø±\n",
      "text after tokens : ['Ù„ÙŠØ¯Ø±', 'Ù…Ø´Ø±ÙˆØ¹', 'Ø§Ù„ØªØ®Ø±Ø¬', 'Ø§Ø­Ù…Ø¯', 'Ø§Ø´Ø±Ù', 'Ø§Ø­Ù…Ø¯', 'Ø§Ù„Ø³ÙŠØ¯', 'ÙˆÙƒØ§Ù†', 'ØªÙŠÙ…', 'ÙŠØªÙƒÙˆÙ†', '8', 'Ø§Ø´Ø®Ø§Øµ', 'Ø§Ù„Ù„ÙŠØ¯Ø±']\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the Arabic text you want to process: \")\n",
    "Arabic_text_preprocessing(input_text,flage=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c95a3",
   "metadata": {},
   "source": [
    "POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc3fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preform POS\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \n",
      "text after tokens : [('Ù„ÙŠØ¯Ø±', 'JJ'), ('Ù…Ø´Ø±ÙˆØ¹', 'NNP'), ('Ø§Ù„ØªØ®Ø±Ø¬', 'NNP'), ('Ø§Ø­Ù…Ø¯', 'NNP'), ('Ø§Ø´Ø±Ù', 'NNP'), ('Ø§Ø­Ù…Ø¯', 'NNP'), ('Ø§Ù„Ø³ÙŠØ¯', 'NNP'), ('ÙˆÙƒØ§Ù†', 'NNP'), ('ØªÙŠÙ…', 'NNP'), ('ÙŠØªÙƒÙˆÙ†', 'VBD'), ('8', 'CD'), ('Ø§Ø´Ø®Ø§Øµ', 'NNS'), ('Ø§Ù„Ù„ÙŠØ¯Ø±', 'VBP')]\n"
     ]
    }
   ],
   "source": [
    "Arabic_text_preprocessing(\"Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø± \",flage=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96c98566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the Arabic text you want to process:  Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preform POS\n",
      "text before : Ù„ÙŠØ¯Ø± Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬ Ø§Ø­Ù…Ø¯ Ø§Ø´Ø±Ù Ø§Ø­Ù…Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¹Ù„Ù‰ ÙˆÙƒØ§Ù† ØªÙŠÙ… ÙŠØªÙƒÙˆÙ† Ù…Ù† 8 Ø§Ø´Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù„ÙŠØ¯Ø±\n",
      "text after tokens : [('Ù„ÙŠØ¯Ø±', 'JJ'), ('Ù…Ø´Ø±ÙˆØ¹', 'NNP'), ('Ø§Ù„ØªØ®Ø±Ø¬', 'NNP'), ('Ø§Ø­Ù…Ø¯', 'NNP'), ('Ø§Ø´Ø±Ù', 'NNP'), ('Ø§Ø­Ù…Ø¯', 'NNP'), ('Ø§Ù„Ø³ÙŠØ¯', 'NNP'), ('ÙˆÙƒØ§Ù†', 'NNP'), ('ØªÙŠÙ…', 'NNP'), ('ÙŠØªÙƒÙˆÙ†', 'VBD'), ('8', 'CD'), ('Ø§Ø´Ø®Ø§Øµ', 'NNS'), ('Ø§Ù„Ù„ÙŠØ¯Ø±', 'VBP')]\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the Arabic text you want to process: \")\n",
    "Arabic_text_preprocessing(input_text,flage=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a73fd8",
   "metadata": {},
   "source": [
    "                                    English\n",
    "PorterStemmer                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdb6c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def English_text_preprocessing(text,flage=1):\n",
    "    '''\n",
    "    Flage Number\n",
    "    1: PorterStemmer\n",
    "    2: SnowballStemmer\n",
    "    3: WordNetLemmatizer\n",
    "    4: POS\n",
    "    '''\n",
    "    text1=text\n",
    "    #The regular expression [^\\w\\s] is used to match any character that is not a word character (\\w) or a whitespace character (\\s).\n",
    "    text = re.sub(r'[^\\w\\s]', '',text)\n",
    "    #splitting sentence into tokens\n",
    "    text=word_tokenize(text.lower())\n",
    "    #remove stopwords\n",
    "    english_stop=set(stopwords.words('english'))\n",
    "    text=[i for i in text if i not in english_stop]\n",
    "    #stemming of each word\n",
    "    if flage<=3:\n",
    "        if flage==1:\n",
    "            stem=PorterStemmer()\n",
    "            text=[stem.stem(i) for i in text]\n",
    "            print('Perform PorterStemmer')\n",
    "        elif flage==2:\n",
    "            stem=SnowballStemmer('english')\n",
    "            text=[stem.stem(i) for i in text]\n",
    "            print('Perform SnowballStemmer')\n",
    "        else:\n",
    "            #Lemmatizer of each word\n",
    "            lemmatizer=WordNetLemmatizer()\n",
    "            text=[lemmatizer.lemmatize(i) for i in text]\n",
    "            print('Perform WordNetLemmatizer')\n",
    "        print(\"text before :\",text1)\n",
    "        print('text after :',' '.join(text))\n",
    "        print('text after tokens :',text)\n",
    "    else:\n",
    "        #part of speech of each word\n",
    "        text=nltk.pos_tag(text)\n",
    "        print('Preform POS')\n",
    "        print(\"text before :\",text1)\n",
    "        print('text after tokens :',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16c16f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform PorterStemmer\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\n",
      "text after : graduat project led ahm ashraf ahm alsay ali team consist 8 peopl leader\n",
      "text after tokens : ['graduat', 'project', 'led', 'ahm', 'ashraf', 'ahm', 'alsay', 'ali', 'team', 'consist', '8', 'peopl', 'leader']\n"
     ]
    }
   ],
   "source": [
    "English_text_preprocessing(\"The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\",flage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b661a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the English text you want to process:  The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform PorterStemmer\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n",
      "text after : graduat project led ahm ashraf ahm alsay ali team consist 8 peopl leader\n",
      "text after tokens : ['graduat', 'project', 'led', 'ahm', 'ashraf', 'ahm', 'alsay', 'ali', 'team', 'consist', '8', 'peopl', 'leader']\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the English text you want to process: \")\n",
    "English_text_preprocessing(input_text,flage=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bf05c",
   "metadata": {},
   "source": [
    "SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fd7f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform SnowballStemmer\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\n",
      "text after : graduat project led ahm ashraf ahm alsay ali team consist 8 peopl leader\n",
      "text after tokens : ['graduat', 'project', 'led', 'ahm', 'ashraf', 'ahm', 'alsay', 'ali', 'team', 'consist', '8', 'peopl', 'leader']\n"
     ]
    }
   ],
   "source": [
    "English_text_preprocessing(\"The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\",flage=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d81efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the English text you want to process:  The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform SnowballStemmer\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n",
      "text after : graduat project led ahm ashraf ahm alsay ali team consist 8 peopl leader\n",
      "text after tokens : ['graduat', 'project', 'led', 'ahm', 'ashraf', 'ahm', 'alsay', 'ali', 'team', 'consist', '8', 'peopl', 'leader']\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the English text you want to process: \")\n",
    "English_text_preprocessing(input_text,flage=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a543b0",
   "metadata": {},
   "source": [
    "WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38add899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform WordNetLemmatizer\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\n",
      "text after : graduation project led ahmed ashraf ahmed alsayed ali team consisted 8 people leader\n",
      "text after tokens : ['graduation', 'project', 'led', 'ahmed', 'ashraf', 'ahmed', 'alsayed', 'ali', 'team', 'consisted', '8', 'people', 'leader']\n"
     ]
    }
   ],
   "source": [
    "English_text_preprocessing(\"The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\",flage=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "460a106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the English text you want to process:  The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform WordNetLemmatizer\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n",
      "text after : graduation project led ahmed ashraf ahmed alsayed ali team consisted 8 people leader\n",
      "text after tokens : ['graduation', 'project', 'led', 'ahmed', 'ashraf', 'ahmed', 'alsayed', 'ali', 'team', 'consisted', '8', 'people', 'leader']\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the English text you want to process: \")\n",
    "English_text_preprocessing(input_text,flage=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5b283",
   "metadata": {},
   "source": [
    "POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dfa8b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preform POS\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\n",
      "text after tokens : [('graduation', 'NN'), ('project', 'NN'), ('led', 'VBD'), ('ahmed', 'JJ'), ('ashraf', 'NN'), ('ahmed', 'VBD'), ('alsayed', 'JJ'), ('ali', 'NN'), ('team', 'NN'), ('consisted', 'VBD'), ('8', 'CD'), ('people', 'NNS'), ('leader', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "English_text_preprocessing(\"The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.â€\",flage=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e403a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the English text you want to process:  The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preform POS\n",
      "text before : The graduation project was led by Ahmed Ashraf Ahmed Al-Sayed Ali, and the team consisted of 8 people with the leader.\n",
      "text after tokens : [('graduation', 'NN'), ('project', 'NN'), ('led', 'VBD'), ('ahmed', 'JJ'), ('ashraf', 'NN'), ('ahmed', 'VBD'), ('alsayed', 'JJ'), ('ali', 'NN'), ('team', 'NN'), ('consisted', 'VBD'), ('8', 'CD'), ('people', 'NNS'), ('leader', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Please enter the English text you want to process: \")\n",
    "English_text_preprocessing(input_text,flage=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acd160",
   "metadata": {},
   "source": [
    "###### Thanks\n",
    "Leader.ð”„ð”¥ð”ªð”¢ð”¡ ð”„ð”°ð”¥ð”¯ð”žð”£\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
